{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28) (50000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3a8ab5d4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import InteractiveSession\n",
    "s = InteractiveSession()\n",
    "from preprocessed_mnist import load_dataset\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "print(X_train.shape, y_train.shape)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[0], cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (None, 28*28)\n",
    "hidden_1 = 1000\n",
    "hidden_2 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>,\n",
       " <tf.Tensor 'Placeholder_1:0' shape=(?, 10) dtype=float32>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_X = tf.placeholder(dtype=tf.float32, shape=input_shape)\n",
    "input_y = tf.placeholder(dtype=tf.float32, shape=(None, 10))\n",
    "\n",
    "input_X, input_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "def preproc_input(X, y):\n",
    "    labels = LabelEncoder().fit_transform(y)[:, None]\n",
    "    y = OneHotEncoder().fit_transform(labels).todense()\n",
    "\n",
    "    X = X.reshape(X.shape[0], 28*28)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = preproc_input(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val, y_val = preproc_input(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 784), (50000, 10))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable_8:0' shape=(784, 1000) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_10:0' shape=(1000, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_9:0' shape=(1, 1000) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_11:0' shape=(1, 10) dtype=float32_ref>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_1 = tf.Variable(dtype=tf.float32, \n",
    "                        initial_value=tf.random_normal(shape=(28*28, hidden_1)), \n",
    "                        expected_shape=(28*28, hidden_1))\n",
    "bias_1 = tf.Variable(dtype=tf.float32, \n",
    "                     initial_value=tf.ones((1, hidden_1)),\n",
    "                     expected_shape=(1, hidden_1))\n",
    "\n",
    "weights_2 = tf.Variable(dtype=tf.float32, \n",
    "                        initial_value=tf.random_normal(shape=(hidden_1, hidden_2)), \n",
    "                        expected_shape=(hidden_1, hidden_2))\n",
    "bias_2 = tf.Variable(dtype=tf.float32, \n",
    "                     initial_value=tf.ones((1, hidden_2)),\n",
    "                     expected_shape=(1, hidden_2))\n",
    "weights_1, weights_2, bias_1, bias_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Softmax_8:0' shape=(?, 1000) dtype=float32>,\n",
       " <tf.Tensor 'Softmax_9:0' shape=(?, 10) dtype=float32>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1 = tf.nn.softmax(tf.add(tf.matmul(input_X, weights_1), bias_1))\n",
    "input_2 = tf.nn.softmax(tf.add(tf.matmul(input_1, weights_2), bias_2))\n",
    "\n",
    "input_1, input_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.softmax_cross_entropy(onehot_labels=input_y, logits=input_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_answers = tf.equal(tf.argmax(input_y, 1), tf.argmax(input_2, 1))\n",
    "acc = tf.reduce_mean(tf.cast(correct_answers, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-319.924 75.1845\n",
      "accuracy = 0.0892999991774559\n",
      "loss at iter 0: 2.3009\n",
      "-266.85 61.8771\n",
      "accuracy = 0.1014999970793724\n",
      "loss at iter 10: 2.2884\n",
      "-241.709 49.1143\n",
      "accuracy = 0.11100000143051147\n",
      "loss at iter 20: 2.3004\n",
      "-227.305 37.2425\n",
      "accuracy = 0.121799997985363\n",
      "loss at iter 30: 2.2917\n",
      "-217.889 25.8747\n",
      "accuracy = 0.13609999418258667\n",
      "loss at iter 40: 2.2617\n",
      "-228.378 15.2191\n",
      "accuracy = 0.15610000491142273\n",
      "loss at iter 50: 2.2642\n",
      "-235.194 4.76494\n",
      "accuracy = 0.17159999907016754\n",
      "loss at iter 60: 2.2591\n",
      "-241.891 -5.63722\n",
      "accuracy = 0.1867000013589859\n",
      "loss at iter 70: 2.2720\n",
      "-263.128 -15.9101\n",
      "accuracy = 0.2013999968767166\n",
      "loss at iter 80: 2.2707\n",
      "-306.293 -25.955\n",
      "accuracy = 0.2184000015258789\n",
      "loss at iter 90: 2.2405\n",
      "-342.659 -36.1223\n",
      "accuracy = 0.23829999566078186\n",
      "loss at iter 100: 2.2513\n",
      "-382.238 -46.3113\n",
      "accuracy = 0.2583000063896179\n",
      "loss at iter 110: 2.2597\n",
      "-414.61 -55.7037\n",
      "accuracy = 0.2808000147342682\n",
      "loss at iter 120: 2.2279\n",
      "-441.565 -65.3749\n",
      "accuracy = 0.29989999532699585\n",
      "loss at iter 130: 2.2309\n",
      "-473.334 -75.5787\n",
      "accuracy = 0.31790000200271606\n",
      "loss at iter 140: 2.2151\n",
      "-519.491 -85.9\n",
      "accuracy = 0.3368000090122223\n",
      "loss at iter 150: 2.1979\n",
      "-585.687 -96.1618\n",
      "accuracy = 0.3549000024795532\n",
      "loss at iter 160: 2.1918\n",
      "-640.304 -105.812\n",
      "accuracy = 0.3711000084877014\n",
      "loss at iter 170: 2.1587\n",
      "-711.224 -115.718\n",
      "accuracy = 0.39070001244544983\n",
      "loss at iter 180: 2.1882\n",
      "-787.564 -125.424\n",
      "accuracy = 0.4081000089645386\n",
      "loss at iter 190: 2.1628\n",
      "-875.779 -135.328\n",
      "accuracy = 0.4255000054836273\n",
      "loss at iter 200: 2.1634\n",
      "-951.869 -144.67\n",
      "accuracy = 0.44760000705718994\n",
      "loss at iter 210: 2.1817\n",
      "-1021.97 -153.753\n",
      "accuracy = 0.4675999879837036\n",
      "loss at iter 220: 2.1500\n",
      "-1105.4 -162.657\n",
      "accuracy = 0.48669999837875366\n",
      "loss at iter 230: 2.1681\n",
      "-1203.6 -172.337\n",
      "accuracy = 0.5027999877929688\n",
      "loss at iter 240: 2.1745\n",
      "-1294.74 -181.76\n",
      "accuracy = 0.5181000232696533\n",
      "loss at iter 250: 2.0661\n",
      "-1384.3 -190.304\n",
      "accuracy = 0.5328999757766724\n",
      "loss at iter 260: 2.0997\n",
      "-1487.68 -198.569\n",
      "accuracy = 0.5479999780654907\n",
      "loss at iter 270: 2.1006\n",
      "-1589.26 -206.535\n",
      "accuracy = 0.5575000047683716\n",
      "loss at iter 280: 2.0873\n",
      "-1683.57 -214.892\n",
      "accuracy = 0.571399986743927\n",
      "loss at iter 290: 2.1248\n",
      "-1762.66 -222.544\n",
      "accuracy = 0.5817000269889832\n",
      "loss at iter 300: 2.1113\n",
      "-1839.29 -229.812\n",
      "accuracy = 0.593999981880188\n",
      "loss at iter 310: 2.0666\n",
      "-1952.91 -237.451\n",
      "accuracy = 0.6049000024795532\n",
      "loss at iter 320: 2.0613\n",
      "-2043.08 -244.604\n",
      "accuracy = 0.6182000041007996\n",
      "loss at iter 330: 2.0730\n",
      "-2123.09 -251.545\n",
      "accuracy = 0.6287999749183655\n",
      "loss at iter 340: 2.1053\n",
      "-2184.76 -258.403\n",
      "accuracy = 0.6359000205993652\n",
      "loss at iter 350: 2.0708\n",
      "-2247.35 -265.329\n",
      "accuracy = 0.64410001039505\n",
      "loss at iter 360: 2.0102\n",
      "-2336.76 -272.306\n",
      "accuracy = 0.6527000069618225\n",
      "loss at iter 370: 2.0464\n",
      "-2431.22 -278.891\n",
      "accuracy = 0.6601999998092651\n",
      "loss at iter 380: 2.0520\n",
      "-2510.63 -285.127\n",
      "accuracy = 0.6658999919891357\n",
      "loss at iter 390: 2.0173\n",
      "-2584.57 -291.142\n",
      "accuracy = 0.6735000014305115\n",
      "loss at iter 400: 2.0273\n",
      "-2663.78 -297.001\n",
      "accuracy = 0.679099977016449\n",
      "loss at iter 410: 2.0671\n",
      "-2755.04 -302.722\n",
      "accuracy = 0.6845999956130981\n",
      "loss at iter 420: 1.9984\n",
      "-2845.99 -308.867\n",
      "accuracy = 0.6895999908447266\n",
      "loss at iter 430: 1.9907\n",
      "-2935.82 -314.844\n",
      "accuracy = 0.6945000290870667\n",
      "loss at iter 440: 1.9599\n",
      "-3042.58 -320.77\n",
      "accuracy = 0.6987000107765198\n",
      "loss at iter 450: 1.9754\n",
      "-3114.68 -326.046\n",
      "accuracy = 0.7038000226020813\n",
      "loss at iter 460: 1.9468\n",
      "-3181.18 -331.276\n",
      "accuracy = 0.7077999711036682\n",
      "loss at iter 470: 1.9700\n",
      "-3241.45 -336.392\n",
      "accuracy = 0.7141000032424927\n",
      "loss at iter 480: 1.9611\n",
      "-3308.24 -341.01\n",
      "accuracy = 0.7174000144004822\n",
      "loss at iter 490: 1.9380\n",
      "-3366.64 -345.676\n",
      "accuracy = 0.7215999960899353\n",
      "loss at iter 500: 1.9398\n",
      "-3421.95 -350.396\n",
      "accuracy = 0.7232999801635742\n",
      "loss at iter 510: 2.0115\n",
      "-3469.86 -354.8\n",
      "accuracy = 0.7260000109672546\n",
      "loss at iter 520: 1.9046\n",
      "-3531.71 -359.403\n",
      "accuracy = 0.7307000160217285\n",
      "loss at iter 530: 1.9573\n",
      "-3608.41 -364.208\n",
      "accuracy = 0.7335000038146973\n",
      "loss at iter 540: 1.9245\n",
      "-3672.44 -368.972\n",
      "accuracy = 0.7369999885559082\n",
      "loss at iter 550: 1.9011\n",
      "-3756.74 -373.817\n",
      "accuracy = 0.7404000163078308\n",
      "loss at iter 560: 1.8569\n",
      "-3827.73 -378.17\n",
      "accuracy = 0.7430999875068665\n",
      "loss at iter 570: 1.9481\n",
      "-3876.66 -382.398\n",
      "accuracy = 0.7444999814033508\n",
      "loss at iter 580: 1.9601\n",
      "-3916.14 -386.375\n",
      "accuracy = 0.7465000152587891\n",
      "loss at iter 590: 1.9262\n",
      "-3943.31 -390.477\n",
      "accuracy = 0.7470999956130981\n",
      "loss at iter 600: 1.9054\n",
      "-3994.11 -394.603\n",
      "accuracy = 0.7506999969482422\n",
      "loss at iter 610: 1.8835\n",
      "-4045.32 -398.412\n",
      "accuracy = 0.7523999810218811\n",
      "loss at iter 620: 1.9022\n",
      "-4090.66 -402.11\n",
      "accuracy = 0.7559000253677368\n",
      "loss at iter 630: 1.8486\n",
      "-4130.87 -405.751\n",
      "accuracy = 0.7587000131607056\n",
      "loss at iter 640: 1.9200\n",
      "-4180.71 -409.343\n",
      "accuracy = 0.7666000127792358\n",
      "loss at iter 650: 1.8656\n",
      "-4236.93 -413.159\n",
      "accuracy = 0.7713000178337097\n",
      "loss at iter 660: 1.8954\n",
      "-4283.08 -417.118\n",
      "accuracy = 0.7732999920845032\n",
      "loss at iter 670: 1.8843\n",
      "-4321.26 -420.679\n",
      "accuracy = 0.7763000130653381\n",
      "loss at iter 680: 1.8704\n",
      "-4359.86 -424.104\n",
      "accuracy = 0.7786999940872192\n",
      "loss at iter 690: 1.8112\n",
      "-4399.21 -427.3\n",
      "accuracy = 0.7807000279426575\n",
      "loss at iter 700: 1.8654\n",
      "-4452.5 -430.645\n",
      "accuracy = 0.7825999855995178\n",
      "loss at iter 710: 1.8650\n",
      "-4505.05 -434.351\n",
      "accuracy = 0.7853999733924866\n",
      "loss at iter 720: 1.8594\n",
      "-4555.32 -438.375\n",
      "accuracy = 0.7854999899864197\n",
      "loss at iter 730: 1.8712\n",
      "-4607.56 -442.217\n",
      "accuracy = 0.7871999740600586\n",
      "loss at iter 740: 1.8221\n",
      "-4658.79 -445.644\n",
      "accuracy = 0.7900000214576721\n",
      "loss at iter 750: 1.8298\n",
      "-4697.42 -448.957\n",
      "accuracy = 0.792900025844574\n",
      "loss at iter 760: 1.8348\n",
      "-4735.42 -452.164\n",
      "accuracy = 0.7925999760627747\n",
      "loss at iter 770: 1.8652\n",
      "-4767.56 -455.451\n",
      "accuracy = 0.7950999736785889\n",
      "loss at iter 780: 1.8058\n",
      "-4802.64 -458.772\n",
      "accuracy = 0.7968000173568726\n",
      "loss at iter 790: 1.7817\n",
      "-4826.43 -462.169\n",
      "accuracy = 0.7983999848365784\n",
      "loss at iter 800: 1.8725\n",
      "-4851.39 -465.242\n",
      "accuracy = 0.7989000082015991\n",
      "loss at iter 810: 1.8157\n",
      "-4876.56 -468.414\n",
      "accuracy = 0.8001999855041504\n",
      "loss at iter 820: 1.8411\n",
      "-4902.22 -471.896\n",
      "accuracy = 0.8009999990463257\n",
      "loss at iter 830: 1.8713\n",
      "-4932.42 -475.533\n",
      "accuracy = 0.8040000200271606\n",
      "loss at iter 840: 1.8086\n",
      "-4990.74 -479.364\n",
      "accuracy = 0.8062000274658203\n",
      "loss at iter 850: 1.8040\n",
      "-5039.43 -482.666\n",
      "accuracy = 0.8159000277519226\n",
      "loss at iter 860: 1.7897\n",
      "-5082.33 -485.636\n",
      "accuracy = 0.8188999891281128\n",
      "loss at iter 870: 1.7244\n",
      "-5133.41 -488.745\n",
      "accuracy = 0.821399986743927\n",
      "loss at iter 880: 1.8151\n",
      "-5179.44 -492.044\n",
      "accuracy = 0.8240000009536743\n",
      "loss at iter 890: 1.8112\n",
      "-5225.15 -495.473\n",
      "accuracy = 0.8256000280380249\n",
      "loss at iter 900: 1.8263\n",
      "-5262.87 -498.627\n",
      "accuracy = 0.82669997215271\n",
      "loss at iter 910: 1.7786\n",
      "-5300.53 -501.967\n",
      "accuracy = 0.8277000188827515\n",
      "loss at iter 920: 1.8031\n",
      "-5337.42 -505.406\n",
      "accuracy = 0.8282999992370605\n",
      "loss at iter 930: 1.7548\n",
      "-5377.36 -508.636\n",
      "accuracy = 0.8296999931335449\n",
      "loss at iter 940: 1.7804\n",
      "-5408.3 -511.74\n",
      "accuracy = 0.832099974155426\n",
      "loss at iter 950: 1.7909\n",
      "-5440.98 -514.842\n",
      "accuracy = 0.8341000080108643\n",
      "loss at iter 960: 1.7948\n",
      "-5485.68 -517.866\n",
      "accuracy = 0.8375999927520752\n",
      "loss at iter 970: 1.7585\n",
      "-5520.87 -521.256\n",
      "accuracy = 0.838699996471405\n",
      "loss at iter 980: 1.7778\n",
      "-5553.03 -524.539\n",
      "accuracy = 0.8384000062942505\n",
      "loss at iter 990: 1.7281\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(1000):\n",
    "    indices = np.random.choice(X_train.shape[0], 100)\n",
    "    s.run(optimizer, {input_X: X_train[indices], input_y: y_train[indices]})\n",
    "    loss_i = s.run(loss, {input_X: X_train[indices], input_y: y_train[indices]})\n",
    "    if i % 10 == 0:         \n",
    "        print(weights_1.eval().sum(), weights_2.eval().sum())\n",
    "        accuracy = s.run(acc, feed_dict={input_X: X_val, input_y: y_val})\n",
    "        print(f'accuracy = {accuracy}')\n",
    "        print(\"loss at iter %i: %.4f\" % (i, loss_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.230221\n"
     ]
    }
   ],
   "source": [
    "s.run(tf.global_variables_initializer())\n",
    "res = s.run(loss_custom, feed_dict={input_X: X_train, input_y: y_train})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23022071"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean_6:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_custom = tf.reduce_mean((-1) * tf.multiply(input_y, tf.log(input_2)))\n",
    "loss_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'softmax_cross_entropy_loss_1/value:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_realised = tf.losses.softmax_cross_entropy(input_y, input_2)\n",
    "loss_realised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean_7:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_alien = tf.reduce_mean(-1*tf.nn.softmax_cross_entropy_with_logits(logits=input_2, labels=input_y))\n",
    "loss_alien"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
